{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look into data structure and how everything is stored. We have 495 parquet files. Each seperated into \"mc_truth\" and \"photons\". Each file contains 200 neutrino injection events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at \"photons\" first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "file_path = \"/ceph/work/SATORI/alex/sim_new/sim_3/output/hits/photon_000.parquet\"\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=200, compact=False)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(f\"\\n===== EVENT {i} =====\")\n",
    "    pp.pprint(df[\"photons\"].iloc[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at \"mc_truth\". We can see true energy in here. That will be our y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "                                                                                                                                                                    \n",
    "file_path = \"/ceph/work/SATORI/alex/sim_new/sim_3/output/hits/photon_000.parquet\"\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=200, compact=False)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(f\"\\n===== EVENT {i} =====\")\n",
    "    pp.pprint(df[\"mc_truth\"].iloc[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know how many hits we have and what's the spread of the hits. Good info to have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"/ceph/work/SATORI/alex/sim_new/sim_3/output/hits\"\n",
    "PATTERN = \"photon_*.parquet\"\n",
    "\n",
    "def count_hits():\n",
    "    files = sorted(glob.glob(os.path.join(DATA_DIR, PATTERN)))\n",
    "    if not files:\n",
    "        print(\"No parquet files found.\")\n",
    "        return\n",
    "\n",
    "    total_events = 0\n",
    "    events_with_hits = 0\n",
    "    total_hits = 0\n",
    "    hits_per_event = []\n",
    "\n",
    "    for f in tqdm(files, desc=\"Processing files\"):\n",
    "        df = pd.read_parquet(f, columns=[\"photons\"])\n",
    "        for photons in df[\"photons\"]:\n",
    "            total_events += 1\n",
    "\n",
    "            n_hits = len(photons[\"t\"])\n",
    "            hits_per_event.append(n_hits)\n",
    "\n",
    "            if n_hits > 0:\n",
    "                events_with_hits += 1\n",
    "                total_hits += n_hits\n",
    "\n",
    "    hits_per_event = np.array(hits_per_event)\n",
    "\n",
    "    print(\"\\n===== SUMMARY =====\")\n",
    "    print(\"Total events:\", total_events)\n",
    "    print(\"Events with â‰¥1 hit:\", events_with_hits)\n",
    "    print(\"Fraction with hits:\", events_with_hits / total_events)\n",
    "    print(\"Total photon hits:\", total_hits)\n",
    "    print(\"Average hits per event:\", hits_per_event[hits_per_event > 0].mean() if events_with_hits > 0 else 0)\n",
    "    print(\"Median hits per event:\", np.median(hits_per_event[hits_per_event > 0]) if events_with_hits > 0 else 0)\n",
    "\n",
    "    # Optional: histogram\n",
    "    hist, bin_edges = np.histogram(hits_per_event, bins=[0,1,10,50,100,500,1000,5000,10000])\n",
    "    print(\"\\nHits per event histogram (bin counts):\")\n",
    "    for b_start, b_end, count in zip(bin_edges[:-1], bin_edges[1:], hist):\n",
    "        print(f\"{int(b_start):5d} - {int(b_end):5d}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_hits()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the CNN, we need to decide the size of our tensor. let's look at the time spread of our hits to determine this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"/ceph/work/SATORI/alex/sim_new/sim_3/output/hits\"\n",
    "files = sorted(glob.glob(os.path.join(DATA_DIR, \"photon_*.parquet\")))\n",
    "\n",
    "durations = []\n",
    "\n",
    "for f in tqdm(files[:499]): \n",
    "    df = pd.read_parquet(f, columns=[\"photons\"])\n",
    "    for ph in df[\"photons\"]:\n",
    "        t = ph[\"t\"]\n",
    "        if len(t) > 0:\n",
    "            durations.append(t.max() - t.min())\n",
    "\n",
    "durations = np.array(durations)\n",
    "print(\"Number of events with hits:\", len(durations))\n",
    "print(\"Min duration:\", durations.min())\n",
    "print(\"Max duration:\", durations.max())\n",
    "print(\"Mean duration:\", durations.mean())\n",
    "print(\"Median duration:\", np.median(durations))\n",
    "print(\"95th percentile duration:\", np.percentile(durations, 95))\n",
    "print(\"99th percentile duration:\", np.percentile(durations, 99))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 99th percdntile is 3348, everything greater are extream cases. We choose 3500 as T_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
